{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RayEmb Inference Notebook\n",
    "This notebook demonstrates how to use the RayEmb model for inference.\n",
    "We will use the RealDeepFluoro dataset for this demonstration. But you can use any other data that matches the inference function signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/pragyan/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/pragyan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/pragyan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/pragyan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "INFO:dinov2:using MLP layer as FFN\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "import nibabel as nib\n",
    "\n",
    "from diffdrr.pose import convert\n",
    "from rayemb.models import RayEmb, FixedLandmark\n",
    "from rayemb.dataset import SyntheticCTPelvic1KDataset, RealDeepFluoroDataset\n",
    "from rayemb.utils import setup_logger, cosine_similarity, find_batch_peak_coordinates_maxval\n",
    "\n",
    "logger = setup_logger(__name__)\n",
    "\n",
    "# Model parameters\n",
    "checkpoint_path = '../checkpoints/rayemb-ctpelvic1k.ckpt'\n",
    "device = 'cuda'\n",
    "image_size = 224\n",
    "emb_dim = 32\n",
    "\n",
    "# Dataset parameters\n",
    "specimen_id = 'specimen_2'\n",
    "num_samples = 300\n",
    "h5_dir = '../data/ipcai_2020_full_res_data.h5'\n",
    "template_dir = '../data/deepfluoro_templates'\n",
    "\n",
    "model = RayEmb.load_from_checkpoint(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    map_location=torch.device(device),\n",
    "    similarity_fn=cosine_similarity,\n",
    "    image_size=image_size,\n",
    "    emb_dim=emb_dim,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataset = RealDeepFluoroDataset(\n",
    "    specimen_id=specimen_id,\n",
    "    num_samples=num_samples,\n",
    "    h5_dir=h5_dir,\n",
    "    sampling_distance=1,\n",
    "    template_dir=template_dir,\n",
    "    sample_only_visible=True,\n",
    "    image_size=image_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idx = 0\n",
    "data = dataset[data_idx]\n",
    "\n",
    "img_target = data[\"img\"][0].to(device).double()[None, None, ...]\n",
    "# specimen = dataset.specimens[data[\"specimen_id\"]]\n",
    "gt_pose = data[\"diffdrr_pose\"]\n",
    "gt_pose = convert(gt_pose, parameterization='matrix').to(device)\n",
    "gt_vol_landmarks = data[\"gt_vol_landmarks\"].unsqueeze(0).to(device)\n",
    "\n",
    "for key, value in data.items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        data[key] = value.to(device).float()\n",
    "\n",
    "specimen_id = data[\"specimen_id\"]\n",
    "img_id = data[\"img_id\"]\n",
    "imgs = data[\"img\"]\n",
    "templates = data[\"templates\"]\n",
    "projection_matrices = data[\"projection_matrices\"]\n",
    "sampled_points = data[\"sampled_points\"][:, :-1]\n",
    "img_sensor_size = data[\"img_sensor_size\"][0].item()\n",
    "source_to_detector_distance = data[\"source_to_detector_distance\"]\n",
    "specimen_id = data[\"specimen_id\"]\n",
    "vol_landmark = data[\"gt_vol_landmarks\"].cpu().numpy()\n",
    "proj_landmark = data[\"gt_proj_landmarks\"].cpu().numpy()\n",
    "query_projection_matrix = data[\"query_projection_matrix\"]\n",
    "K = data[\"K\"].cpu().numpy()\n",
    "diffdrr_pose = data[\"diffdrr_pose\"]\n",
    "gt_extrinsic = data[\"extrinsic\"]\n",
    "gt_proj_point = data[\"proj_point_img\"].cpu().numpy()\n",
    "pixel_size = data[\"pixel_size\"].item()\n",
    "flip_xz = data[\"flip_xz\"].to(device)\n",
    "translate = data[\"translate\"].to(device)\n",
    "\n",
    "sims = model.inference(imgs, templates, sampled_points, projection_matrices, return_features=False)\n",
    "proj_point, max_vals = find_batch_peak_coordinates_maxval(sims)\n",
    "proj_points_np = proj_point.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1882731/591260869.py:24: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "error = np.linalg.norm(gt_proj_point - proj_points_np, axis=-1)\n",
    "\n",
    "fig = plt.figure(figsize=(50, 50))\n",
    "num_cols = 5\n",
    "num_rows = 5\n",
    "axes = fig.subplots(num_rows, num_cols)\n",
    "axes = axes.flatten()\n",
    "sims_np = sims.cpu().numpy()\n",
    "img_np = imgs.cpu().numpy()[0]\n",
    "for i in range(num_rows * num_cols):\n",
    "    axes[i].imshow(img_np, cmap=\"gray\")\n",
    "    axes[i].imshow(sims_np[i], cmap=\"jet\", alpha=0.5)\n",
    "    axes[i].scatter(gt_proj_point[i, 0], gt_proj_point[i, 1], s=100,  # s is the size of the marker\n",
    "                    facecolors='magenta', edgecolors='w', linewidths=5,  # no fill, blue edge, width of 2\n",
    "                    label='GT')\n",
    "\n",
    "    # Plotting the projected points as green circles\n",
    "    axes[i].scatter(proj_points_np[i, 0], proj_points_np[i, 1], s=100,\n",
    "                    facecolors='cyan', edgecolors='w', linewidths=5,  # no fill, green edge, width of 2\n",
    "                    label='Projected')\n",
    "    axes[i].set_title(f\"{i} {max_vals[i]:.4f}\")\n",
    "    axes[i].axis(\"off\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
