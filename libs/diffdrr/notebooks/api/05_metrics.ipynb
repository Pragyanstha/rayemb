{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c823ed02",
   "metadata": {},
   "source": [
    "---\n",
    "title: metrics\n",
    "description: Loss functions for registration and reconstruction tasks\n",
    "output-file: metrics.html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbb10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28930479-d8e6-4859-b5de-38a5350f510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NormalizedCrossCorrelation2d(torch.nn.Module):\n",
    "    \"\"\"Compute Normalized Cross Correlation between two batches of images.\"\"\"\n",
    "\n",
    "    def __init__(self, patch_size=None, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        if self.patch_size is not None:\n",
    "            x1 = to_patches(x1, self.patch_size)\n",
    "            x2 = to_patches(x2, self.patch_size)\n",
    "        assert x1.shape == x2.shape, \"Input images must be the same size\"\n",
    "        _, c, h, w = x1.shape\n",
    "        x1, x2 = self.norm(x1), self.norm(x2)\n",
    "        score = torch.einsum(\"b...,b...->b\", x1, x2)\n",
    "        score /= c * h * w\n",
    "        return score\n",
    "\n",
    "    def norm(self, x):\n",
    "        mu = x.mean(dim=[-1, -2], keepdim=True)\n",
    "        var = x.var(dim=[-1, -2], keepdim=True, correction=0) + self.eps\n",
    "        std = var.sqrt()\n",
    "        return (x - mu) / std\n",
    "\n",
    "class MultiscaleNormalizedCrossCorrelation2d(torch.nn.Module):\n",
    "    \"\"\"Compute Normalized Cross Correlation between two batches of images at multiple scales.\"\"\"\n",
    "\n",
    "    def __init__(self, patch_sizes=[None], patch_weights=[1.0], eps=1e-5):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(patch_sizes) == len(patch_weights), \"Each scale must have a weight\"\n",
    "        self.nccs = [NormalizedCrossCorrelation2d(patch_size) for patch_size in patch_sizes]\n",
    "        self.patch_weights = patch_weights\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        scores = []\n",
    "        for weight, ncc in zip(self.patch_weights, self.nccs):\n",
    "            scores.append(weight * ncc(x1, x2))\n",
    "        return torch.stack(scores, dim=0).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b3608-8d2a-43b6-b902-9f905877dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "def to_patches(x, patch_size):\n",
    "    x = x.unfold(2, patch_size, step=1).unfold(3, patch_size, step=1).contiguous()\n",
    "    return rearrange(x, \"b c p1 p2 h w -> b (c p1 p2) h w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39dd1d-ab40-4f7b-926d-dff305b9ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GradientNormalizedCrossCorrelation2d(NormalizedCrossCorrelation2d):\n",
    "    \"\"\"Compute Normalized Cross Correlation between the image gradients of two batches of images.\"\"\"\n",
    "\n",
    "    def __init__(self, patch_size=None, sigma=1.0, **kwargs):\n",
    "        super().__init__(patch_size, **kwargs)\n",
    "        self.sobel = Sobel(sigma)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        return super().forward(self.sobel(x1), self.sobel(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6317e99-8a0a-4dce-959f-904c21595d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "\n",
    "\n",
    "class Sobel(torch.nn.Module):\n",
    "    def __init__(self, sigma):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.filter = torch.nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=2,  # X- and Y-gradients\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,  # Return images of the same size as inputs\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        Gx = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]]).to(torch.float32)\n",
    "        Gy = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]]).to(torch.float32)\n",
    "        G = torch.stack([Gx, Gy]).unsqueeze(1)\n",
    "        self.filter.weight = torch.nn.Parameter(G, requires_grad=False)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = gaussian_blur(img, 5, self.sigma)\n",
    "        x = self.filter(img)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c67f91-d50f-4b68-a24a-58390558837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0063, -0.0137,  0.0008, -0.0102,  0.0019, -0.0029, -0.0012,  0.0017])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.randn(8, 1, 128, 128)\n",
    "x2 = torch.randn(8, 1, 128, 128)\n",
    "\n",
    "ncc = NormalizedCrossCorrelation2d()\n",
    "ncc(x1, x2)\n",
    "\n",
    "ncc = NormalizedCrossCorrelation2d(eps=1e-1)\n",
    "ncc(x1, x2)\n",
    "\n",
    "ncc = NormalizedCrossCorrelation2d(patch_size=9)\n",
    "ncc(x1, x2)\n",
    "\n",
    "msncc = MultiscaleNormalizedCrossCorrelation2d(patch_sizes=[9, None], patch_weights=[0.5, 0.5])\n",
    "msncc(x1, x2)\n",
    "\n",
    "gncc = GradientNormalizedCrossCorrelation2d()\n",
    "gncc(x1, x2)\n",
    "\n",
    "gncc = GradientNormalizedCrossCorrelation2d(patch_size=9)\n",
    "gncc(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ae1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043c1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
